\section{Initialization and Scoping}

Chombo provides no special MPI initialization function.
This is done intentionally to make it easier for
Chombo users to interface with other parallel
packages (which may provide their own special 
initialization routines) in the same code that
they use with Chombo.

If one is using Chombo in a parallel code, 
one must somehow call \verb/MPI_Init/ before instantiating any Chombo
data objects (whether that is in the context of some other package's
initialization routines or not). One must also call 
\verb/MPI_Finalize/ after all Chombo data objects have gone
out of scope.   To make sure these get done
in the correct order, some care in scoping is required.
Some Chombo classes, by necessity, call MPI functions
in their destructors.  One must be careful to make 
certain that all Chombo classes go out of scope 
{\it before} \verb/MPI_Finalize/ gets called.  A simple
way to do this is shown here:
\small \begin{verbatim}
int main(int argc, char* argv[])
{
#ifdef MPI
MPI_Init(&argc, &argv);
#endif
//this sets the beginning of the scope of Chombo objects
{

LevelData<FArrayBox> phi, rhs;
...do a bunch of calculations...

//this sets the end of the scope of Chombo objects
}
#ifdef MPI
MPI_Finalize();
#endif
return(0);
}
\end{verbatim} \normalsize
In this example, \verb/MPI_Init/ and \verb/MPI_Finalize/
get used in the normal sense but the  braces between them
force Chombo destructors to be called before 
\verb/MPI_Finalize/ is called.


\section{Overview of Chombo Data Parallelism}

Our parallel model is box-based SPMD parallel programming.  
Distributed data always lives in containers ({\tt LayoutData},
{\tt BoxLayoutData}, and {\tt LevelData} are the containers).
All processors execute the same code.  
All processors have access to
the unions of rectangles (the {\tt BoxLayout}s and the 
{\tt DisjointBoxLayout}s) and what processors each rectangle's 
data lives upon.  The data associated with  the rectangles
is distributed among processors.   We use smart iterators
over our data objects which stop at the boxes which live
on the current processor.  To be complete,
broadcast and gather functions are included for
situations where parallelism cannot be hidden by iterators.
As of release 3.2 it is also possible to use hybrid parallelism with
OpenMP. When using Chombo's native iterators, it suffices to modify
looping over the boxes. We use the same iterators, however, the boxes
are indexed explicitly to let OpenMP know that they are
parallelizable. The lower level code has been made thread-safe and
examples of hybrid parallelism are available in {\tt
  AMRTimeDependent} and {\tt AMRElliptic/AMRPoissonOp.*}. Note that
the memory tracking feature of Chombo is not yet usable with hybrid
parallelism.

As in the serial case,
the class {\tt BoxLayout} represents an arbitrary
union of rectangles and  {\tt LayoutData} and {\tt BoxLayoutData} 
both represent data built upon such a union. 
The class {\tt DisjointBoxLayout} represents a disjoint 
union of rectangles and  {\tt LevelData} 
represents data built upon a disjoint union.   The data
in these data holders is distributed among processors according
to the boxes that the data lives upon.   A box's worth of data 
is considered atomic in this model.

Also, as in the serial case, the data holders
have very different communication patterns even
though all the holders distribute their data among processors.
{\tt LayoutData} is a distributed 
object that can not be   involved in communication (it can
be neither the source nor destination in 
{\tt copyTo} or {\tt exchange}).  
A {\tt BoxLayoutData} object may be only the destination
of a {\tt copyTo} function and {\tt exchange} is not defined
for {\tt BoxLayoutData}.  A {\tt LevelData} object, because
it is built upon a disjoint layout,  may be involved
in any of our forms of data communication.  
Chombo also contains two templated communication functions that 
sometimes cannot be avoided in parallel applications: broadcast
and gather.  See section 
\ref{BroadcastGatherSection} for details.

\section{Box-processor assignment}
\label{AssignmentSection}

A {\tt BoxLayout} is a set of boxes and processor 
assignments.  We construct the layout with two matching lists:
a {\tt Vector} of boxes and 
a {\tt Vector} of integers which represent the processor 
into which data over the box will be distributed.  
Chombo does provide a  load balancing function 
(see section \ref{LoadBalanceSection} for details)
which can generate these processor assignments.
This function is not integrated into the {\tt BoxLayout}
class for the express purpose of providing a user
the ability to use her own load balancing algorithm
to generate processor assignments.  

For now, assume we have a \verb/vbox = Vector<Box>/ which 
represents the grids from  which we generate a 
{\tt BoxLayout} and we have a \verb/vint = Vector<int>/
which represents the processor mapping we desire
(we want data which resides on \verb/vbox[i]/ to reside
on processor \verb/vint[i]/).  A {\tt BoxLayout} can
be constructed either incrementally:
\small \begin{verbatim}
BoxLayout boxlayout; //layout
Vector<Box> vbox;  //grids
Vector<int> vint;  //processor assignments
for(int ibox = 0; ibox < vint.size(); ibox++)
   boxlayout.addBox(vbox[ibox], vint[ibox]);
boxlayout.close();
\end{verbatim} \normalsize
or all at once:
\small \begin{verbatim}
Vector<Box> vbox;  //grids
Vector<int> vint;  //processor assignments
BoxLayout boxlayout(vbox, vint);
boxlayout.close();
\end{verbatim} \normalsize
Note that the {\tt close} function must
be called in either case 
after all the boxes are added.   A {\tt DisjointBoxLayout}
is constructed in exactly the same way.  If the boxes
which are added to a {\tt DisjointBoxLayout} are not
disjoint (i.e. they have some nontrivial intersection)
a runtime error is raised when {\tt close()} is called.

\section{LoadBalance}
\label{LoadBalanceSection}

Chombo provides a load balancing function         
(called {\tt LoadBalance}) to compute an assignment
of boxes to processors for an AMR mesh hierarchy.  
The assignment is made  to balance the computation
workload on each processor (i.e., make it as even as possible).
The meshes in the AMR hierarchy are represented using
\verb/Vector< Vector< Box > >/.
The computational workload is a real number for each box in the
hierarchy,  represented as a \verb/Vector< Vector <Real> >/.
This is an input which the user may prescribe to her own needs.
Load determination is far too application-specific 
to permit any kind of general solution.
The resulting assignment is an integer for each box in the hierarchy,
which gives the processor number (starting at zero) on which each box
will reside.  
{\tt LoadBalance} uses the Kernighan-Lin algorithm for
solving knapsack problems.  This algorithm has been used
quite successfully for load balancing parallel AMR calculations
\cite{Crutchfield91}. 
The interface to {\tt LoadBalance} is given by
\small \begin{verbatim}
int LoadBalance(Vector<int>& procAssignments, 
          const Vector<Box>& boxes).
\end{verbatim} \normalsize
Here {\tt boxes} are the input grids and
{\tt procAssignments} are the processor numbers
that go with each box.
The load for a given 
used by this version of {\tt LoadBalance} is the
number of points in the box.  There is a more elaborate
version of {\tt LoadBalance} in Chombo which allows
the user to input the loads for each box.  See the
reference manual for details.
The return value of {\tt LoadBalance} is an error code.  
If {\tt LoadBalance} exited without error, 0 is returned.
If anything other than zero is returned, the output values are
undefined. An example of how to use {\tt LoadBalance} is shown in
\ref{loadbalancefig}.
\begin{small}
\begin{figure}
\begin{verbatim}
void setGrids(Vector<DisjointBoxLayout>& vectGrids,
              const Vector<int>&         vectRefRatio, 
              const Vector<Vector<Box>&  VVBoxNew,
              const int& numlevels)
{
  for(int ilev = 0; ilev < numlevels; ilev++)
   {    
        const Vector<Box>& levelGrids = VVBoxNew[ilev];
        Vector<int> procAssign;
        int eekflag = LoadBalance(procAssign, levelGrids);
        assert(eekflag == 0);
        vectGrids[ilev].define(levelGrids, procAssign);
        vectGrids[ilev].close();
   }
}
\end{verbatim}
\hrulefill
\caption{Code snippet to show how LoadBalance is used to 
        transform a list of boxes into {\tt DisjointBoxLayouts}.}
\label{loadbalancefig}
\end{figure}
\end{small}

\section{Broadcast and Gather}
\label{BroadcastGatherSection}

Chombo also contains two templated communication functions that 
sometimes cannot be avoided in parallel applications: broadcast
and gather.  Consider the following example:  suppose one has a 
\verb/LevelData<FArrayBox>/ called {\tt resid} 
and one wants to calculate the  max norm of the data in this
container.  A naive way to do this  would be:
\small \begin{verbatim}
//naive routine to calculate max norm of resid at varNum component
Real maxNorm(LevelData<FArrayBox>& resid, int varNum)
{
  Real maxnorm = 0;
  DataIterator dit = resid.iterator();
  for (dit.reset(); dit.ok(); ++dit)
  {      
    maxnorm = Max(maxnorm, resid[dit()].norm(0, varNum, 1);
  }
  return maxnorm;
}
\end{verbatim} \normalsize
This code is correct in serial and incorrect in parallel.  In
parallel, every processor will have a different value of maxnorm.
To make this code correct, we must {\it gather} all the values 
of maxnorm, calculate the maximum value, and {\it broadcast}
this value to all processors.  

The interface to the templated gather function is as follows:
\small \begin{verbatim}
///gather a_input into  a_outVec on a_dest
template <class T>
void gather(Vector<T>& a_outVec, const T& a_input, int a_dest);
\end{verbatim}\normalsize
This function gathers \verb/a_input/ from every processor into 
\verb/Vector<T> a_outVec/ on processor \verb/a_dest/. 
\verb/a_outVec/ is a vector of length \verb/nProc()/ long
with the value of \verb/a_input/   on every processor in its elements.

The interface to the templated broadcast function is as follows:
\small \begin{verbatim}
///broadcast a_inAndOut to every processor from a_src
template <class T>
void broadcast(T& a_inAndOut,  int a_src);
\end{verbatim}\normalsize
This function broadcasts \verb/a_inAndOut/ from 
processor \verb/a_src/ to all processors
for both \verb/broadcast<T>/ and \verb/gather<T>/.
There are some restrictions on T, which are explained in 
section \ref{LinearSection}.

Here is how to make the previous example work in
parallel:

\small \begin{verbatim}
//correct routine to calculate max norm of resid at varNum variable
Real maxNorm(LevelData<FArrayBox>& resid, int varNum)
{
  Real maxnormLocal = 0;
  DataIterator dit = resid.iterator();
  for (dit.reset(); dit.ok(); ++dit)
  {      
    maxnormLocal = Max(maxnormLocal, resid[dit()].norm(0, varNum, 1);
  }
  //gather all maxnormLocals onto processor 0
  int srcProc = 0;
  Vector<Real> allMaxNorm(numProc());
  gather(allMaxNorm, maxnormLocal, srcProc);
  Real maxnorm = 0;
  if(procID() == srcProc)
  {
    for(int ivec = 0; ivec < numProc(); ivec++)
      maxnorm = Max(maxnorm, allMaxNorm[ivec]);
  }
  
  //broadcast the right answer to all procs
  broadcast(maxnorm, srcProc);
  return maxnorm;
}
\end{verbatim} \normalsize
This example will work in both the serial and parallel cases.


\subsection{linearIn, linearOut, linearSize}
\label{LinearSection}

By ``linearize,'' we mean ``to convert a data structure into
a contiguous block of memory.''
For either \verb/gather<T>/  or  \verb/broadcast<T>/ to work,
T must have the following template functions: 
\begin{itemize}
\item \begin{verbatim} 
int linearSize<T>(const T& inputT)
\end{verbatim}
Return the linear size of the object \verb/inputT/ in bytes.

\item \begin{verbatim} 
void linearIn<T>(T& outputT, 
const void* const inBuf)
\end{verbatim}
Initialize the object \verb/outputT/ from the byte stream
in \verb/inBuf/.  

\item \begin{verbatim} 
void linearOut<T>(void* const  outBuf, 
const T& inputT)
\end{verbatim}
Output the object \verb/inputT/ into the byte stream
\verb/outBuf/.  The memory for the buffer is assumed to be
allocated elsewhere.
\end{itemize}
Chombo provides these
functions for {\tt Box, IntVectSet, Real, int} and a templated
function for any \verb/Vector<T>/ (as long as \verb/T/ has
the three functions itself).

